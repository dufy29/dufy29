<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="baidu-site-verification" content="1EB8XoOl0C"><meta name="google-site-verification" content="K7thEgdLm0UfRWJ5MGdF7sCcjClSzAlxFLPv2Oz5CGM"><title> ⭐️训练框架笔记 · Hexo</title><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="description" content="⭐️训练框架笔记 - John Doe"><meta name="keywords"><meta name="author" content="John Doe"><link rel="short icon" href="https://bubuzou.oss-cn-shenzhen.aliyuncs.com/blog/202010/favicon.ico"><link rel="stylesheet" href="https://bubuzou.oss-cn-shenzhen.aliyuncs.com/blog/202010/bubuzou.css"><link rel="search" type="application/opensearchdescription+xml" href="http://example.com/atom.xml" title="Hexo"><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src='//unpkg.com/valine/dist/Valine.min.js'></script><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
</head><body><header><div class="header row"> <a href="/" class="logo-link"><img src="/images/logo.png"></a><ul id="nav_list" class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" data-hover="博文" class="nav-list-link">博文</a></li><li class="nav-list-item"><a href="/archives/" target="_self" data-hover="归档" class="nav-list-link">归档</a></li><li class="nav-list-item"><a href="/about/" target="_self" data-hover="关于" class="nav-list-link">关于</a></li></ul><div class="search"><a id="search_btn" href="#search"></a></div><div id="nav_btn" class="nav-btn"><span></span><span></span><span></span></div></div></header><div class="row scroll-con"><section class="container"><!-- for archive page--><div id="postAr" class="post"><article class="post-block"><h1 class="post-title">⭐️训练框架笔记</h1><div class="post-info">2021-07-20</div><div class="post-content"><p>TF源码：<a target="_blank" rel="noopener" href="https://github.com/tensorflow/tensorflow">https://github.com/tensorflow/tensorflow</a></p>
<span id="more"></span>



<ul>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/328674159">PyTorch 源码解读系列</a></li>
</ul>
<p><img src="/2021/07/20/%E3%80%90ML%E3%80%91%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/aa.jpeg"></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/20b92c29d571">看PyTorch源代码的心路历程</a></li>
<li><a target="_blank" rel="noopener" href="http://blog.ezyang.com/2019/05/pytorch-internals/">pytorch internals</a></li>
</ul>
<h2 id="AI编译器"><a href="#AI编译器" class="headerlink" title="AI编译器"></a>AI编译器</h2><p>📚 <a target="_blank" rel="noopener" href="https://deeplearningsystems.ai/">Deep Learning Systems: Algorithms, Compilers, and Processors for Large-Scale Production</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/404714949">The Deep Learning Compiler: A Comprehensive Survey论文翻译</a></p>
<p><a target="_blank" rel="noopener" href="https://oldpan.me/archives/the-first-step-towards-tvm-1">一步一步解读神经网络编译器TVM(一)——一个简单的例子</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/wendaocp/article/details/113762416">TVM（端到端深度学习编译器）简介</a></p>
<p>视频：2021，<a target="_blank" rel="noopener" href="https://www.zhihu.com/zvideo/1368678126411800576">Chris ASPLOS Keynote - 编译器的黄金时代</a></p>
<p>​    PPT:: <a target="_blank" rel="noopener" href="https://docs.google.com/presentation/d/1ZMtzT6nmfvNOlIaHRzdaXpFeaAklcT7DvfGjhgpzcxk/edit#slide=id.p">https://docs.google.com/presentation/d/1ZMtzT6nmfvNOlIaHRzda…</a></p>
<p>视频：2019,  <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=kFT54hO1X8M&ab_channel=UBCComputerScience">David Patterson - A New Golden Age for Computer Architecture: History, Challenges and Opportunities</a></p>
<p>知乎：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/367035973">看Chris Lattner在ASPLOS演讲有感</a></p>
<p>视频：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Bp4y1t7Cw/?spm_id_from=333.337.search-card.all.click&vd_source=abeb4ad4122e4eff23d97059cf088ab4">【硬核课程】编译器设计【使用教材：编译器设计(第2版)】</a></p>
<p>视频：<a target="_blank" rel="noopener" href="https://space.bilibili.com/1540261574/channel/collectiondetail?sid=708685">由先进编译实验室的成员给大家分享TVM编译器系列</a></p>
<p>陈天奇AI编译器系列视频： <a target="_blank" rel="noopener" href="https://www.youtube.com/@mlc-ai2867">An Introduction to Machine Learning Compilation (MLC)</a></p>
<p>​    PPT: <a target="_blank" rel="noopener" href="https://mlc.ai/summer22/schedule">https://mlc.ai/summer22/schedule</a></p>
<p><img src="/2021/07/20/%E3%80%90ML%E3%80%91%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/image-20230225224535866.png" alt="image-20230225224535866"></p>
<p><img src="/2021/07/20/%E3%80%90ML%E3%80%91%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/image-20230225224659436.png" alt="image-20230225224659436"></p>
<p><img src="/2021/07/20/%E3%80%90ML%E3%80%91%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/image-20230225225004583.png" alt="image-20230225225004583"></p>
<p><strong>传统编译器与AI编译器的区别</strong></p>
<blockquote>
<p>IR的全称是Intermediate Representation，翻译为中间表示</p>
</blockquote>
<p><img src="/2021/07/20/%E3%80%90ML%E3%80%91%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/ccc.png"></p>
<h3 id="后端优化"><a href="#后端优化" class="headerlink" title="后端优化"></a><strong>后端优化</strong></h3><p>后端优化作为AI编译器跟硬件之间的相连接的模块，更多的是算子或者Kernel进行优化，而优化之前需要把计算图转换称为调度树等IR格式，然后针对每一个算子/Kernel进行循环优化、指令优化和内存优化等技术。</p>
<p><strong>算子优化</strong></p>
<p>AutoKernel：  <a target="_blank" rel="noopener" href="https://autokernel-docs-en.readthedocs.io/zh_CN/latest/index.html">https://autokernel-docs-en.readthedocs.io/zh_CN/latest/index.html</a></p>
<p><strong>LLVM</strong></p>
<p>LLVM 架构：</p>
<p><img src="/2021/07/20/%E3%80%90ML%E3%80%91%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/ddd.png"></p>
<p>运行过程：</p>
<p><img src="/2021/07/20/%E3%80%90ML%E3%80%91%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/wes22.png"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">dufy@MBP chap7 % clang -ccc-print-phases elf_demo.c</span><br><span class="line">               +- 0: input, &quot;elf_demo.c&quot;, c</span><br><span class="line">            +- 1: preprocessor, &#123;0&#125;, cpp-output</span><br><span class="line">         +- 2: compiler, &#123;1&#125;, ir</span><br><span class="line">      +- 3: backend, &#123;2&#125;, assembler</span><br><span class="line">   +- 4: assembler, &#123;3&#125;, object</span><br><span class="line">+- 5: linker, &#123;4&#125;, image</span><br><span class="line">6: bind-arch, &quot;x86_64&quot;, &#123;5&#125;, image</span><br></pre></td></tr></table></figure>

<p><img src="/2021/07/20/%E3%80%90ML%E3%80%91%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/image-20230225111951070.png" alt="image-20230225111951070"></p>
<p>整个后端流水线用到了四种不同层次的指令表示:</p>
<p>内存中的LLVM IR，SelectionDAG 节点，MachineInstr，和 MCInst。</p>
<p><img src="/2021/07/20/%E3%80%90ML%E3%80%91%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/image-20230225112315204.png" alt="image-20230225112315204"></p>
<p><strong>LLVM 应用</strong></p>
<ul>
<li>XLA,加速线性代数</li>
<li>JAX, = XLA + Autograd</li>
<li>TensorFlow</li>
<li>TVM</li>
<li>Julia, HPC</li>
</ul>
<h2 id="pytorch-源码"><a href="#pytorch-源码" class="headerlink" title="pytorch 源码"></a>pytorch 源码</h2><p>核心文件夹主要是c10、aten、torch、caffe2.</p>
<p>为什么将c10放到最前面呢？</p>
<p>因为官方已经表明<strong>c10</strong>目录是最重要的源代码文件夹，也就是几乎所有的源代码都与这里的代码有关系,比如我们的类型定义，Pytorch最重要的<strong>Tensor</strong>的内存分配方式等等，都在这个文件夹中，官方也说到了，之后会慢慢将Aten中的代码移至这个文件夹，也就是说这个文件夹将包含Pytorch中最核心的代码。</p>
<p>而<strong>Aten</strong>文件夹则包含了一些实现了<strong>Tensor</strong>的底层(和c10类似)，也包括了很多的层前向代码和后向实现的代码(例如卷积层的前向和后向操作代码),包括CPU和GPU端，总之都是C++的核心操作代码。</p>
<p><strong>torch</strong>文件夹也同样重要，其中主要包含了一些稍微高层些的操作函数，例如<strong>torch.ones</strong>等，有C++和Python端，也包括了Python核心代码和包装代码，如果我们使用python版Pytorch的话，与这些代码接触就比较密切了。</p>
<p>而<strong>Caffe2</strong>则不用多说，caffe2则主要针对移动端设计了很多优化后的运算代码，模型融合、模型量化等等的代码，其后端有QNNPACK等一些针对移动端的底层运算库(有开发人员说GLOW也在caffe2后端考虑之内)。</p>
<p>检查Pytorch安装是否成功：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">print(torch.cuda.is_available())</span><br><span class="line">print(torch.backends.cudnn.is_acceptable(torch.cuda.FloatTensor(1)))</span><br><span class="line">print(torch.backends.cudnn.version())</span><br><span class="line">print(torch.version.cuda)</span><br><span class="line"></span><br><span class="line"># 输出</span><br><span class="line">True  # 出现Turn说明cuda正常</span><br><span class="line">Ture  # 出现Ture说明cudnn正常</span><br><span class="line">7301  # 这是我的版本号</span><br><span class="line">9.0.176</span><br></pre></td></tr></table></figure>





<h2 id="pytorch多卡训练"><a href="#pytorch多卡训练" class="headerlink" title="pytorch多卡训练"></a>pytorch多卡训练</h2><p>以数据并行为例， 参考哔站 <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1xZ4y1S7dG/?spm_id_from=pageDriver&vd_source=abeb4ad4122e4eff23d97059cf088ab4">33、完整讲解PyTorch多GPU分布式训练代码编写</a></p>
<p><strong>单机单卡</strong></p>
<p><a target="_blank" rel="noopener" href="https://github.com/dufy29/ai-frame/blob/5c5f2c89868ea916df8d97f2577a021eb210ad8c/pytorch/pytorch%20imdb-%E5%A4%9AGPU%E8%AE%AD%E7%BB%83%E4%BB%A3%E7%A0%81demo.py">github示例代码</a></p>
<p><img src="/2021/07/20/%E3%80%90ML%E3%80%91%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/aa1.jpeg"></p>
<p><strong>单机多卡</strong></p>
<p><a target="_blank" rel="noopener" href="https://github.com/dufy29/ai-frame/blob/main/pytorch/pytorch%20imdb-%E5%A4%9AGPU%E8%AE%AD%E7%BB%83%E4%BB%A3%E7%A0%81demo.py">推荐 DDP实现</a></p>
<p><img src="/2021/07/20/%E3%80%90ML%E3%80%91%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/qq.jpeg"></p>
<ul>
<li><del>torch.nn.DataParallel() 实现</del></li>
</ul>
<p><img src="/2021/07/20/%E3%80%90ML%E3%80%91%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/as.png"></p>
<ul>
<li>DDP: torch.nn.parallel.DistributedDataParallel() 实现</li>
</ul>
<p><img src="/2021/07/20/%E3%80%90ML%E3%80%91%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/image-20230225232911774.png" alt="image-20230225232911774"></p>
<p><img src="/2021/07/20/%E3%80%90ML%E3%80%91%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/aa2.jpeg"></p>
<p><img src="/2021/07/20/%E3%80%90ML%E3%80%91%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/aa3.jpeg"></p>
<p><strong>多机多卡</strong></p>
<p><img src="/2021/07/20/%E3%80%90ML%E3%80%91%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/qw.jpeg"></p>
<h2 id="TF-系统架构"><a href="#TF-系统架构" class="headerlink" title="TF 系统架构"></a>TF 系统架构</h2><p><img src="/2021/07/20/%E3%80%90ML%E3%80%91%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/sda.jpeg"></p>
<p>详细的如下：</p>
<p><img src="/2021/07/20/%E3%80%90ML%E3%80%91%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/fg.jpeg"></p>
<p>对于 TensorFlow，C API 是衔接前后端系统的桥梁。理解 C API 的设计，基本能够猜测前后端系统的行为</p>
<p><strong>技术栈</strong></p>
<p>下图按照系统的层次结构展示了 TensorFlow 的技术栈，构成了 TensorFlow 生态系统的核心。</p>
<p><img src="/2021/07/20/%E3%80%90ML%E3%80%91%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/sfd.jpeg"></p>
<h2 id="TF编程模型"><a href="#TF编程模型" class="headerlink" title="TF编程模型"></a>TF<strong>编程模型</strong></h2><p><strong>基于数据流的通信拓扑</strong></p>
<p>TensorFlow 是一个使用数据流图 (Dataflow Graph) 表达数值计算的开源软件库。它使 用节点表示抽象的数学计算，并使用 OP 表达计算的逻辑;而边表示节点间传递的数据流， 并使用 Tensor 表达数据的表示。数据流图是一种有向无环图 (DAG)，当图中的 OP 按 照特定的拓扑排序依次被执行时，Tensor 在图中流动形成数据流，TensorFlow 因此而得名。</p>
<p>使用节点表示抽象计算，边表示数据流(Tensor)</p>
<blockquote>
<p>下图展示了 MNIST 手写识别应用的数据流图。在该模型 中，前向子图使用了 2 层全连接网络，分别为 ReLU 层和 Softmax 层。随后，使用 SGD 的 优化算法，构建了与前向子图对应的反向子图，用于计算训练参数的梯度。最后，根据参数 更新法则，构造训练参数的更新子图，完成训练参数的迭代更新。</p>
</blockquote>
<p><img src="/2021/07/20/%E3%80%90ML%E3%80%91%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/aaz.gif"></p>
<p>OP 是最小的抽象计算单元，支持构造复杂的网络模型</p>
<p>TF 支持 OP 扩展，Kernel 扩展，Device 扩展，通信协议的扩展;</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><a target="_blank" rel="noopener" href="https://tf.wiki/zh_hans/">https://tf.wiki/zh_hans/</a></li>
</ol>
<p><img src="/2021/07/20/%E3%80%90ML%E3%80%91%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/1.jpeg"></p>
<ol start="2">
<li><a target="_blank" rel="noopener" href="https://github.com/dragen1860/Deep-Learning-with-TensorFlow-book">https://github.com/dragen1860/Deep-Learning-with-TensorFlow-book</a></li>
<li>30天吃掉那只Tensorflow2</li>
</ol>
<p><a target="_blank" rel="noopener" href="https://jackiexiao.github.io/eat_tensorflow2_in_30_days/">https://jackiexiao.github.io/eat_tensorflow2_in_30_days/</a></p>
<ol start="5">
<li>[<a target="_blank" rel="noopener" href="https://www.cnblogs.com/yao62995/p/5773578.html">图解tensorflow源码] [原创] Tensorflow 图解分析 （Session, Graph, Kernels, Devices）</a></li>
</ol>
<p><img src="/2021/07/20/%E3%80%90ML%E3%80%91%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/12.jpeg"></p>
<ol start="6">
<li>csdn博主 pytorch 专栏：<a target="_blank" rel="noopener" href="https://blog.csdn.net/scar2016/category_10900277.html?spm=1001.2014.3001.5482">https://blog.csdn.net/scar2016/category_10900277.html?spm=1001.2014.3001.5482</a></li>
</ol>
<p><img src="/2021/07/20/%E3%80%90ML%E3%80%91%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/ada.jpeg"></p>
</div></article></div><div class="right-container"><div class="widget"><div id="arAnchorBar"></div></div><div class="widget"><div class="tagcloud"><h4>标签云</h4><a href="/tags/C/" style="font-size: 10px;">C</a> <a href="/tags/CS/" style="font-size: 15px;">CS</a> <a href="/tags/CSAPP/" style="font-size: 10px;">CSAPP</a> <a href="/tags/CV/" style="font-size: 10px;">CV</a> <a href="/tags/Django/" style="font-size: 10px;">Django</a> <a href="/tags/GPU/" style="font-size: 10px;">GPU</a> <a href="/tags/Git/" style="font-size: 10px;">Git</a> <a href="/tags/HTML/" style="font-size: 10px;">HTML</a> <a href="/tags/Hadoop/" style="font-size: 10px;">Hadoop</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/Pytorch/" style="font-size: 10px;">Pytorch</a> <a href="/tags/TensorFlow/" style="font-size: 10px;">TensorFlow</a> <a href="/tags/book/" style="font-size: 15px;">book</a> <a href="/tags/c/" style="font-size: 10px;">c++</a> <a href="/tags/flask/" style="font-size: 10px;">flask</a> <a href="/tags/linux/" style="font-size: 10px;">linux</a> <a href="/tags/mysql/" style="font-size: 10px;">mysql</a> <a href="/tags/nlp/" style="font-size: 15px;">nlp</a> <a href="/tags/paper/" style="font-size: 10px;">paper</a> <a href="/tags/shell/" style="font-size: 10px;">shell</a> <a href="/tags/%E4%BD%93%E7%B3%BB%E5%8C%96/" style="font-size: 10px;">体系化</a> <a href="/tags/%E5%85%89%E7%BA%BF%E8%BF%BD%E8%B8%AA/" style="font-size: 10px;">光线追踪</a> <a href="/tags/%E5%88%86%E8%AF%8D/" style="font-size: 10px;">分词</a> <a href="/tags/%E5%8A%9B%E6%89%A3/" style="font-size: 10px;">力扣</a> <a href="/tags/%E5%B7%A5%E5%85%B7/" style="font-size: 10px;">工具</a> <a href="/tags/%E5%B9%B6%E5%8F%91/" style="font-size: 10px;">并发</a> <a href="/tags/%E6%80%9D%E7%BB%B4/" style="font-size: 10px;">思维</a> <a href="/tags/%E6%8E%A8%E8%8D%90/" style="font-size: 10px;">推荐</a> <a href="/tags/%E6%90%9C%E7%B4%A2/" style="font-size: 10px;">搜索</a> <a href="/tags/%E6%91%98%E8%A6%81/" style="font-size: 10px;">摘要</a> <a href="/tags/%E6%95%B0%E5%AD%A6/" style="font-size: 10px;">数学</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" style="font-size: 10px;">数据结构</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">机器学习</a> <a href="/tags/%E6%A0%91%E8%8E%93%E6%B4%BE/" style="font-size: 10px;">树莓派</a> <a href="/tags/%E6%A1%86%E6%9E%B6/" style="font-size: 10px;">框架</a> <a href="/tags/%E7%88%AC%E8%99%AB/" style="font-size: 15px;">爬虫</a> <a href="/tags/%E7%94%B5%E5%BD%B1/" style="font-size: 10px;">电影</a> <a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" style="font-size: 10px;">目标检测</a> <a href="/tags/%E7%A1%AC%E4%BB%B6/" style="font-size: 10px;">硬件</a> <a href="/tags/%E7%AE%80%E5%8E%86/" style="font-size: 10px;">简历</a> <a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 20px;">算法</a> <a href="/tags/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6/" style="font-size: 10px;">自动驾驶</a> <a href="/tags/%E8%87%AA%E5%AD%A6/" style="font-size: 10px;">自学</a> <a href="/tags/%E8%A7%84%E8%8C%83/" style="font-size: 10px;">规范</a> <a href="/tags/%E9%87%8F%E5%AD%90%E5%8A%9B%E5%AD%A6/" style="font-size: 10px;">量子力学</a></div></div></div></section></div><div class="right-menu"></div><div class="modal search-modal"><div class="input-field"><input type="text" id="search_input"><label for="search-input">搜索</label></div><div id="search_result" class="search-result"></div></div><div class="blog-overlay"></div><footer class="row"><div class="footer-con"><div class="paginator"><a href="/2021/07/26/%E3%80%90%E7%BD%91%E7%BB%9C%E3%80%91%E7%BD%91%E9%A1%B5%E5%B1%95%E7%A4%BA/" title="⭐️网页展示" class="prev">PREV</a><a href="/2021/06/29/%E3%80%90ML%E3%80%91%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%95%B0%E5%AD%A6/" title="⭐️机器学习中的数学" class="next">NEXT</a></div><div class="copyright"><p>© 2016 - 2023 <a target="_blank">John Doe</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> <br> and <a href="https://github.com/Bulandent/hexo-theme-bubuzou" target="_blank">hexo-theme-bubuzou</a></p><p> <span style="padding-right: 6px;">闽ICP备16007301号-2</span></p></div><div class="totop"><i></i></div></div></footer><script async src="//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><script src="https://bubuzou.oss-cn-shenzhen.aliyuncs.com/blog/202010/jquery-1.8.2.min.js"></script><script src="https://bubuzou.oss-cn-shenzhen.aliyuncs.com/blog/202010/articleCatalog.js"></script><script src="https://bubuzou.oss-cn-shenzhen.aliyuncs.com/blog/202010/main.js"></script><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-65933410-1",'auto');ga('send','pageview');</script></body></html>